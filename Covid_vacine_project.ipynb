{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Covid_vacine_project.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUn6KSc4kNgA"
   },
   "source": [
    "# Analiza rozmów na temat szczepionek Covid na Twitterze "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI6VqqCMkRQq"
   },
   "source": [
    "Analiza rozmów na temat szczepionek Covid na Twitterze\n",
    "\n",
    "• Wykrywanie sentymentu\n",
    "\n",
    "• Natężenie twittów w czasie\n",
    "\n",
    "• Followers and mentions (graf)\n",
    "\n",
    "• Analiza współwystępujących hashtagów\n",
    "\n",
    "• Zróżnicowanie geopgraficzne (patrz: https://www.kaggle.com/gpreda/covid-world-vaccination-progress)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "owsuCl_dkAry"
   },
   "source": [
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from tweepy import OAuthHandler, Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "\n"
   ],
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XU4WezXAqldY"
   },
   "source": [
    "consumer_key = 'Rtc2Q6UT6suUSRUZAOrAc7Cvy'\n",
    "consumer_secret = 'HUB2y0VadL4PiAOvpWEvQAielzZEw2g5DHXwgBy3v2eLtYerJh'\n",
    "access_token = '1348985626750820355-XxasjfmxmwqkTo4ktct2YKfGy3dIAS'\n",
    "access_secret = 'UICiTvf4yXd6iZgJ2qp3684zHounvbtz71oDsfPmgJh5u'"
   ],
   "execution_count": 81,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GIxtlUq-uzhX"
   },
   "source": [
    "class TwitterStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing live tweets.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n",
    "        # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "        listener = StdOutListener(fetched_tweets_filename)\n",
    "        auth  = OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_secret)\n",
    "        stream = Stream(auth, listener) \n",
    "        stream.filter(track=hash_tag_list)\n",
    "\n",
    "class StdOutListener(StreamListener):\n",
    "    \"\"\"\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "    def __init__(self, fetched_tweets_filename):\n",
    "        self.fetched_tweets_filename = fetched_tweets_filename\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            #print(data)\n",
    "            response_parser(data)\n",
    "            # with open(self.fetched_tweets_filename, 'a') as tf:\n",
    "            #      tf.write(data)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data %s\" % str(e))\n",
    "        return True   \n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "\n",
    "# functions for preparing list of hast tags\n",
    "def drop_duplicates(x):\n",
    "  \"\"\"\n",
    "  Function that drops duplicated objects withint the list.\n",
    "  :Usage: Support function for read_hash_tag_list.\n",
    "  \"\"\"\n",
    "  return list(dict.fromkeys(x))\n",
    "\n",
    "def read_hash_tag_list(file):\n",
    "  \"\"\"\n",
    "  Function for reading hashtag from the txt file \n",
    "  and drops duplicated hash tags from the list. \n",
    "  \"\"\"\n",
    "  hash_tag_list = []\n",
    "  count = 0\n",
    "  with open(file, \"r\") as fp:\n",
    "    for line in fp:\n",
    "      count += 1\n",
    "      hash_tag_list.append(line.strip())\n",
    "  print(\"before drop_duplicates\", len(hash_tag_list))\n",
    "  hash_tag_list = drop_duplicates(hash_tag_list)\n",
    "  print(\"after drop_duplicates\", len(hash_tag_list))\n",
    "  return hash_tag_list"
   ],
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0b_xU4B2Iefr"
   },
   "source": [
    "def write_json(new_data, filename='parsed_tweets.json'):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(new_data, f, indent=4)\n",
    "def response_parser(data):\n",
    "    # with open('tweets.json') as json_file:\n",
    "    #     data = json.load(json_file)\n",
    "    #\n",
    "    data=json.loads(data)\n",
    "\n",
    "    if data['entities']['hashtags']:\n",
    "        single_data = {}\n",
    "        single_data['id'] = data['id']\n",
    "        single_data['created_at'] = data['created_at']\n",
    "        single_data['text'] = data['text']\n",
    "        single_data['geo'] = data['geo']\n",
    "        single_data['coordinates'] = data['coordinates']\n",
    "\n",
    "        if data['place']:\n",
    "            single_data['place_name']=data['place']['name']\n",
    "            single_data['place_full_name']=data['place']['full_name']\n",
    "            single_data['place_country']=data['place']['country_code']\n",
    "            if data['place']['bounding_box']:\n",
    "                single_data['place_coordinates']=data['place']['bounding_box']['coordinates'][0]\n",
    "            else:\n",
    "                single_data['place_coordinates']=''\n",
    "        else:\n",
    "            single_data['place_name']=''\n",
    "            single_data['place_full_name']=''\n",
    "            single_data['place_country']=''\n",
    "            single_data['place_coordinates']=''\n",
    "        #single_data['place'] = data['place']\n",
    "        single_data['filter_level'] = data['filter_level']\n",
    "        single_data['lang'] = data['lang']\n",
    "        single_data['quote_count'] = data['quote_count']\n",
    "        single_data['reply_count'] = data['reply_count']\n",
    "        single_data['retweet_count'] = data['retweet_count']\n",
    "        single_data['favorite_count'] = data['favorite_count']\n",
    "        single_data['user_id'] = data['user']['id']\n",
    "        single_data['user_name'] = data['user']['name']\n",
    "        single_data['user_description'] = data['user']['description']\n",
    "        single_data['user_created_at'] = data['user']['created_at']\n",
    "        single_data['user_followers_count'] = data['user']['followers_count']\n",
    "        single_data['user_friends_count'] = data['user']['friends_count']\n",
    "        single_data['user_favourites_count'] = data['user']['favourites_count']\n",
    "        single_data['user_statuses_count'] = data['user']['statuses_count']\n",
    "        hashtags_list = []\n",
    "        for hashtag in data['entities']['hashtags']:\n",
    "            hashtags_list.append(hashtag['text'])\n",
    "\n",
    "        single_data['hashtags_list'] = hashtags_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        with open('parsed_tweets.json') as json_file:\n",
    "            parsed_tweets = json.load(json_file)\n",
    "            parsed_tweets.append(single_data)\n",
    "\n",
    "        write_json(parsed_tweets)"
   ],
   "execution_count": 83,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1KGNsbDUmoO",
    "outputId": "26e29728-2eb5-40d0-fc11-9a44ef57b2fb"
   },
   "source": [
    "hash_tag_list = read_hash_tag_list(\"hasztag_list.txt\")\n",
    "print(len(hash_tag_list))"
   ],
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop_duplicates 92\n",
      "after drop_duplicates 81\n",
      "81\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "4Lk39wTJxkLw",
    "outputId": "99948cb7-a5e7-456d-843a-aac20fe71fcb",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "\n",
    "#hash_tag_list = read_hash_tag_list(\"/content/hash_tags.txt\")\n",
    "print(hash_tag_list)\n",
    "fetched_tweets_filename = \"tweets.json\"\n",
    "\n",
    "#Staring the stream\n",
    "twitter_streamer = TwitterStreamer()\n",
    "auth  = OAuthHandler(consumer_key, consumer_secret)\n",
    "twitter_streamer.stream_tweets(fetched_tweets_filename, hash_tag_list)\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#vacinaja', '#vacinaparatodos', '#vacina', '#vaccineforall', '#vaccinesaveslives', '#vaccinepassports', '#vacinasim', '#vacinaparatodosjÃ¡', '#CoronaVac', '#AstraZeneca', '#CovidVaccines', '#Pzifer', '#janssen', '#VaccineforSouthAfrica', '#COVID19vaccines', '#COVID19Vaccination', '#szczepimysie', '#szczepionka', '#vaccines', '#vaccination', '#NarodowyProgramSzczepieÅ„', '#SzczepieniaSeniorÃ³w', '#vaccinated', '#vaccinatedagainstcovid19', '#VaccinesWork', '#VaccinesSaveLives', '#PfizerBioNTech', '#Moderna', '#LargestVaccineDrive', '#VacunaCOVID19', '#vaccinecovid19', '#Vacunacion', '#VacunacionVip', '#vacunaparatodos', '#vaccino', '#VaccinoSospeso', '#Vaccinodromes', '#impfstoff', '#Impfstoffdesaster', '#Impfstoffverteilung', '#vaccine', '#Unite2FightCorona', '#CoronaVirusUpdates', '#FirstDose', '#COVIDVaccine', '#IndiaFightsCorona', '#VaccineAppropriateBehavior', '#vaccinationday', '#VaccineForAll', '#NationalVaccinationDay', '#NationalVaccinationDay2021', '#astrazenecavaccine', '#getvaccinated', '#covidvacination2ndjab', '#CovidVaccine', '#PfizerVaccine', '#GetTheShot', '#VaccineMaitri', '#covidvaccine', '#COVID19Vaccine', '#GetVaccinatedIfYouCan', '#GetVaccinated', '#OxfordAstraZeneca', '#Astrazeneca', '#astrazennica', '#VaccineHesitancy', '#FullyVaccinated', '#Pfizer', '#IDoNotConsent', '#vaccinescauseAIDS', '#vaccineskill', '#vaccinescauseautism', '#learntherisk', '#justasking', '#ConstitutionOverCoronavirus', '#vaccineinjury', '#MMR', '#measles', '#antivaxxer', '#antivax', '#vaccinefree']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df=pd.read_json('parsed_tweets.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.count()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}